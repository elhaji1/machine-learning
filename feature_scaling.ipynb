{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature scaling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+o6ocgq+/kM9y+qDTI+Xx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT7pBHkn7AZD"
      },
      "source": [
        "## <font color=\"blue\">Data Preprocessig:Feature Scaling</fon>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdlPLlVY7wdd"
      },
      "source": [
        "La qualité des données est un élément clé dans toute démarche de machine Learning. Toutefois, Le plus souvent, en machine Learning, les jeux de données (Data Set) proviennent avec des ordres de grandeurs différents ce qui peut affaiblir les performances de modélisation (en particulier la lenteur de la convergence d'un algorithme).\n",
        "\n",
        "Le Feature Scaling qui comprend la Standardisation et la Normalisation permet de pallier à ce genre de problème (différence d'echelle des grandeurs).\n",
        "\n",
        "le module sklearn.preprocessing fournit un certain nmobre de classe transformers et un ecrain nombre de routines destinées à feature scaling dont je vous présente dans ce tutoriel:\n",
        "+ **MinMaxeScaler()** \n",
        "+ **MaxAbsScaler()** \n",
        "+ **StandarScaler()**\n",
        "+ **RobustScaler()**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbr3DfmY-E1Z"
      },
      "source": [
        "# <font color=blue>1. MinMaxScaler\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ax9mu-1a-iXB"
      },
      "source": [
        "La classe MinMaxScaler transforme les features en adaptant chacune sur une plage donnée. La plage par défaut est: [-1 , 1]), mais il est possible de changer cette plage via les parametres feature_range=(min, max). La formule utilisé est la suivante:\n",
        "<p>\n",
        "<font color=\"red\">\n",
        "$ X_{scaled}=\\frac{X-X_{min}}{X_{max}-X_{min}}  $ </font>\n",
        "<p>\n",
        "<p>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTA057XcABI9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "695d62fe-b576-4956-a3b5-30327c3db17c"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#création d'un tableau de données non normalisées\n",
        "x=np.array([[140],\n",
        "            [50],\n",
        "            [80],\n",
        "            [20],\n",
        "            [1]])\n",
        "#normalisation à l'aide de la classe MinMaxScaler\n",
        "myscaler=MinMaxScaler()\n",
        "x_scaled=myscaler.fit_transform(x)\n",
        "print(x_scaled)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.        ]\n",
            " [0.35251799]\n",
            " [0.56834532]\n",
            " [0.13669065]\n",
            " [0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB1ekCoqFe-U"
      },
      "source": [
        "# <font color=blue>2. MaxAbsScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj5DsuK1F54o"
      },
      "source": [
        "La classe MaxAbsScaler est utile en présence de valeurs abbérante (outiers). En effet les autres classes utilisant des techniues ayant tendance  à effacer l’impact des outliers, chose qui peut être gênant. La formule utilisée est la suivante:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whzHPG56HmAO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ddf6a24e-cf56-47b9-f6ff-ea42908a920b"
      },
      "source": [
        "#Importation des packages nécessaires\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "#création d'un tableau de données non normalisées\n",
        "x=np.array([[140],\n",
        "            [50],\n",
        "            [80],\n",
        "            [20],\n",
        "            [1]])\n",
        "#normalisation à l'aide de la classe MinMaxScaler\n",
        "myscaler=MaxAbsScaler()\n",
        "x_n=myscaler.fit_transform(x)\n",
        "print(x_n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.        ]\n",
            " [0.35714286]\n",
            " [0.57142857]\n",
            " [0.14285714]\n",
            " [0.00714286]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_15OU6BJj-F"
      },
      "source": [
        "# <font color=blue>3. StandarScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es8pZ3VlE4_D"
      },
      "source": [
        "<font color=\"blue\" size=\"6\"> $ x_{scaled}=\\frac{x_i-\\bar{x} }{\\sigma} $ </Font>\n",
        "\n",
        "+ $ \\bar{x} $: est la moyenne de la série;\n",
        "+ $ \\sigma $: est son écart-type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qC96bkvl3Cl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8f03301b-4d4b-46e4-ef35-f9d75223a9ea"
      },
      "source": [
        "\"\"\"\n",
        "Mise à l'echelle des données avac la classe StandardScaler()\n",
        "\"\"\"\n",
        "#Importation des packages nécessaires\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#création d'un tableau de données\n",
        "x=np.array([[140],\n",
        "            [50],\n",
        "            [80],\n",
        "            [20],\n",
        "            [1]])\n",
        "#scaling à l'aide de la classe StandardScaler\n",
        "myscaler=StandardScaler()\n",
        "x_n=myscaler.fit_transform(x)\n",
        "print(x_n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.67218985]\n",
            " [-0.16762783]\n",
            " [ 0.44564473]\n",
            " [-0.7809004 ]\n",
            " [-1.16930635]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjLO4NonmVzl"
      },
      "source": [
        "# <font color=blue>4. RebustScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YAqf6Z7ldHR"
      },
      "source": [
        "<font color=\"red\">\n",
        "$ X_{scaled}=\\frac{x_i-Q_1(x)}{Q_3(x)-Q_1(x)}  $ </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiMPsOTvmgqD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c587c9a8-0d30-434a-f0de-71291d624aec"
      },
      "source": [
        "\"\"\"\n",
        "Mise à l'echelle des données avac la classe RobustScaler()\n",
        "\"\"\"\n",
        "#Importation des packages nécessaires\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "#création d'un tableau de données initial\n",
        "x=np.array([[140],\n",
        "            [50],\n",
        "            [80],\n",
        "            [20],\n",
        "            [1]])\n",
        "#Mise à l'echelle l'aide de la classe RobustScaler\n",
        "myscaler=RobustScaler()\n",
        "x_n=myscaler.fit_transform(x)\n",
        "print(x_n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.5       ]\n",
            " [ 0.        ]\n",
            " [ 0.5       ]\n",
            " [-0.5       ]\n",
            " [-0.81666667]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx1rIzfiXY0n"
      },
      "source": [
        "# <font color=blue>5. Conclusion</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWEunuXuXyJs"
      },
      "source": [
        "le choix d'une technique de Feature Scaling dépend en grande partie de la nature de votre data set et de ce que vous voulez en faire:\n",
        "\n",
        "+ **MinMaxScaler :** calibre les données sur une plage de valeurs.\n",
        "+ **MaxAbsScaler :** est généralement utilisée quand les données de votre data set données ne sont pas en répartition normale. Tient compte des outliers.\n",
        "+ **StandardScaler :** recalibre les données pour des répartitions normales.\n",
        "+ **RobustScaler :** identique à Min-Max mais utilise l’intervalle interquartile au lieu des valeurs Min et Max."
      ]
    }
  ]
}
